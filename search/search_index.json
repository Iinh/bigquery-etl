{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"BigQuery ETL","title":"BigQuery ETL"},{"location":"#bigquery-etl","text":"","title":"BigQuery ETL"},{"location":"mozfun/bits28/","text":"bits28 The bits28 functions provide an API for working with \"bit pattern\" INT64 fields, as used in the clients_last_seen dataset for desktop Firefox and similar datasets for other applications. A powerful feature of the clients_last_seen methodology is that it doesn't record specific metrics like MAU and WAU directly, but rather each row stores a history of the discrete days on which a client was active in the past 28 days. We could calculate active users in a 10 day or 25 day window just as efficiently as a 7 day (WAU) or 28 day (MAU) window. But we can also define completely new metrics based on these usage histories, such as various retention definitions. The usage history is encoded as a \"bit pattern\" where the physical type of the field is a BigQuery INT64, but logically the integer represents an array of bits, with each 1 indicating a day where the given clients was active and each 0 indicating a day where the client was inactive. days_since_seen (UDF) Return the position of the rightmost set bit in an INT64 bit pattern. To determine this position, we take a bitwise AND of the bit pattern and its complement, then we determine the position of the bit via base-2 logarithm; see https://stackoverflow.com/a/42747608/1260237 See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference SELECT mozfun.bits28.days_since_seen(18) -- >> 1 from_string (UDF) Convert a string representing individual bits into an INT64. Implementation based on https://stackoverflow.com/a/51600210/1260237 See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference active_in_range (UDF) Return a boolean indicating if any bits are set in the specified range of a bit pattern. The start_offset must be zero or a negative number indicating an offset from the rightmost bit in the pattern. n_bits is the number of bits to consider, counting right from the bit at start_offset . See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference range (UDF) Return an INT64 representing a range of bits from a source bit pattern. The start_offset must be zero or a negative number indicating an offset from the rightmost bit in the pattern. n_bits is the number of bits to consider, counting right from the bit at start_offset. See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference SELECT -- Signature is bits28.range(offset_to_day_0, start_bit, number_of_bits) mozfun.bits28.range(days_seen_bits, -13 + 0, 7) AS week_0_bits, mozfun.bits28.range(days_seen_bits, -13 + 7, 7) AS week_1_bits FROM telemetry.clients_last_seen WHERE submission_date > '2020-01-01' to_dates (UDF) Convert a bit pattern into an array of the dates is represents. See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference to_string (UDF) Convert an INT64 field into a 28-character string representing the individual bits. Implementation based on https://stackoverflow.com/a/51600210/1260237 See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference SELECT [mozfun.bits28.to_string(1), mozfun.bits28.to_string(2), mozfun.bits28.to_string(3)] -- >>> ['0000000000000000000000000001', -- '0000000000000000000000000010', -- '0000000000000000000000000011'] retention (UDF) Return a nested struct providing booleans indicating whether a given client was active various time periods based on the passed bit pattern.","title":"bits28"},{"location":"mozfun/bits28/#bits28","text":"The bits28 functions provide an API for working with \"bit pattern\" INT64 fields, as used in the clients_last_seen dataset for desktop Firefox and similar datasets for other applications. A powerful feature of the clients_last_seen methodology is that it doesn't record specific metrics like MAU and WAU directly, but rather each row stores a history of the discrete days on which a client was active in the past 28 days. We could calculate active users in a 10 day or 25 day window just as efficiently as a 7 day (WAU) or 28 day (MAU) window. But we can also define completely new metrics based on these usage histories, such as various retention definitions. The usage history is encoded as a \"bit pattern\" where the physical type of the field is a BigQuery INT64, but logically the integer represents an array of bits, with each 1 indicating a day where the given clients was active and each 0 indicating a day where the client was inactive.","title":"bits28"},{"location":"mozfun/bits28/#days_since_seen-udf","text":"Return the position of the rightmost set bit in an INT64 bit pattern. To determine this position, we take a bitwise AND of the bit pattern and its complement, then we determine the position of the bit via base-2 logarithm; see https://stackoverflow.com/a/42747608/1260237 See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference SELECT mozfun.bits28.days_since_seen(18) -- >> 1","title":"days_since_seen (UDF)"},{"location":"mozfun/bits28/#from_string-udf","text":"Convert a string representing individual bits into an INT64. Implementation based on https://stackoverflow.com/a/51600210/1260237 See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference","title":"from_string (UDF)"},{"location":"mozfun/bits28/#active_in_range-udf","text":"Return a boolean indicating if any bits are set in the specified range of a bit pattern. The start_offset must be zero or a negative number indicating an offset from the rightmost bit in the pattern. n_bits is the number of bits to consider, counting right from the bit at start_offset . See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference","title":"active_in_range (UDF)"},{"location":"mozfun/bits28/#range-udf","text":"Return an INT64 representing a range of bits from a source bit pattern. The start_offset must be zero or a negative number indicating an offset from the rightmost bit in the pattern. n_bits is the number of bits to consider, counting right from the bit at start_offset. See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference SELECT -- Signature is bits28.range(offset_to_day_0, start_bit, number_of_bits) mozfun.bits28.range(days_seen_bits, -13 + 0, 7) AS week_0_bits, mozfun.bits28.range(days_seen_bits, -13 + 7, 7) AS week_1_bits FROM telemetry.clients_last_seen WHERE submission_date > '2020-01-01'","title":"range (UDF)"},{"location":"mozfun/bits28/#to_dates-udf","text":"Convert a bit pattern into an array of the dates is represents. See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference","title":"to_dates (UDF)"},{"location":"mozfun/bits28/#to_string-udf","text":"Convert an INT64 field into a 28-character string representing the individual bits. Implementation based on https://stackoverflow.com/a/51600210/1260237 See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference SELECT [mozfun.bits28.to_string(1), mozfun.bits28.to_string(2), mozfun.bits28.to_string(3)] -- >>> ['0000000000000000000000000001', -- '0000000000000000000000000010', -- '0000000000000000000000000011']","title":"to_string (UDF)"},{"location":"mozfun/bits28/#retention-udf","text":"Return a nested struct providing booleans indicating whether a given client was active various time periods based on the passed bit pattern.","title":"retention (UDF)"},{"location":"mozfun/event_analysis/","text":"event_analysis These functions are specific for use with the events_daily and event_types tables. By themselves, these two tables are nearly impossible to use since the event history is compressed; however, these stored procedures should make the data accessible. The events_daily table is created as a result of two steps: 1. Map each event to a single UTF8 char which will represent it 2. Group each client-day and store a string that records, using the compressed format, that clients' event history for that day. The characters are ordered by the timestamp which they appeared that day. The best way to access this data is to create a view to do the heavy lifting. For example, to see which clients completed a certain action, you can create a view using these functions that knows what that action's representation is (using the compressed mapping from 1.) and create a regex string that checks for the presence of that event. The view makes this transparent, and allows users to simply query a boolean field representing the presence of that event on that day. extract_event_counts (UDF) Extract the events and their counts from an events string. This function explicitly ignores event properties, and retrieves just the counts of the top-level events. Usage extract_event_counts( events STRING ) events - A comma-separated events string, where each event is represented as a string of unicode chars. Example See this dashboard for example usage. extract_event_counts_with_properties (UDF) Extract events with event properties and their associated counts. Also extracts raw events and their counts. This allows for querying with and without properties in the same dashboard. Usage extract_event_counts_with_properties( events STRING ) events - A comma-separated events string, where each event is represented as a string of unicode chars. Example See this query for example usage. Caveats This function extracts both counts for events with each property, and for all events without their properties. This allows us to include both total counts for an event (with any property value), and events that don't have properties. create_events_view (Stored Procedure) Create a view that queries the events_daily table. This view currently supports both funnels and event counts. Funnels are created as a struct, with each step in the funnel as a boolean column in the struct, indicating whether the user completed that step on that day. Event counts are simply integers. Usage create_events_view( view_name STRING, project STRING, dataset STRING, funnels ARRAY<STRUCT< funnel_name STRING, funnel ARRAY<STRUCT< step_name STRING, events ARRAY<STRUCT< category STRING, event_name STRING>>>>>>, counts ARRAY<STRUCT< count_name STRING, events ARRAY<STRUCT< category STRING, event_name STRING>>>> ) view_name : The name of the view that will be created. This view will be in the shared-prod project, in the analysis bucket, and so will be queryable at: sql `moz-fx-data-shared-prod`.analysis.{view_name} project : The project where the dataset is located. dataset : The dataset that must contain both the events_daily and event_types tables. funnels : An array of funnels that will be created. Each funnel has two parts: funnel_name : The name of the funnel is what the column representing the funnel will be named in the view. For example, with the value \"onboarding\" , the view can be selected as follows: sql SELECT onboarding FROM `moz-fx-data-shared-prod`.analysis.{view_name} funnel : The ordered series of steps that make up a funnel. Each step also has: step_name : Used to name the column within the funnel and represents whether the user completed that step on that day. For example, within onboarding a user may have completed_first_card as a step; this can be queried at sql SELECT onboarding.completed_first_step FROM `moz-fx-data-shared-prod`.analysis.{view_name} events : The set of events which indicate the user completed that step of the funnel. Most of the time this is a single event. Each event has a category and event_name . counts : An array of counts. Each count has two parts, similar to funnel steps: count_name : Used to name the column representing the event count. E.g. \"clicked_settings_count\" would be queried at sql SELECT clicked_settings_count FROM `moz-fx-data-shared-prod`.analysis.{view_name} events : The set of events you want to count. Each event has a category and event_name . Recommended Pattern Because the view definitions themselves are not informative about the contents of the events fields, it is best to put your query immediately after the procedure invocation, rather than invoking the procedure and running a separate query. This STMO query is an example of doing so. This allows viewers of the query to easily interpret what the funnel and count columns represent. Structure of the Resulting View The view will be created at `moz-fx-data-shared-prod`.analysis.{event_name}. The view will have a schema roughly matching the following: root |-- submission_date: date |-- client_id: string |-- {funnel_1_name}: record | |-- {funnel_step_1_name} boolean | |-- {funnel_step_2_name} boolean ... |-- {funnel_N_name}: record | |-- {funnel_step_M_name}: boolean |-- {count_1_name}: integer ... |-- {count_N_name}: integer ...dimensions... Funnels Each funnel will be a STRUCT with nested columns representing completion of each step The types of those columns are boolean, and represent whether the user completed that step on that day. STRUCT( completed_step_1 BOOLEAN, completed_step_2 BOOLEAN, ... ) AS funnel_name With one row per-user per-day, you can use COUNTIF(funnel_name.completed_step_N) to query these fields. See below for an example. Event Counts Each event count is simply an INT64 representing the number of times the user completed those events on that day. If there are multiple events represented within one count, the values are summed. For example, if you wanted to know the number of times a user opened or closed the app, you could create a single event count with those two events. event_count_name INT64 Examples The following creates a few fields: - collection_flow is a funnel for those that started creating a collection within Fenix, and then finished, either by adding those tabs to an existing collection or saving it as a new collection. - collection_flow_saved represents users who started the collection flow then saved it as a new collection. - number_of_collections_created is the number of collections created - number_of_collections_deleted is the number of collections deleted CALL mozfun.event_analysis.create_events_view( 'fenix_collection_funnels', 'moz-fx-data-shared-prod', 'org_mozilla_firefox', -- Funnels [ STRUCT( \"collection_flow\" AS funnel_name, [STRUCT( \"started_collection_creation\" AS step_name, [STRUCT('collections' AS category, 'tab_select_opened' AS event_name)] AS events), STRUCT( \"completed_collection_creation\" AS step_name, [STRUCT('collections' AS category, 'saved' AS event_name), STRUCT('collections' AS category, 'tabs_added' AS event_name)] AS events) ] AS funnel), STRUCT( \"collection_flow_saved\" AS funnel_name, [STRUCT( \"started_collection_creation\" AS step_name, [STRUCT('collections' AS category, 'tab_select_opened' AS event_name)] AS events), STRUCT( \"saved_collection\" AS step_name, [STRUCT('collections' AS category, 'saved' AS event_name)] AS events) ] AS funnel) ], -- Event Counts [ STRUCT( \"number_of_collections_created\" AS count_name, [STRUCT('collections' AS category, 'saved' AS event_name)] AS events ), STRUCT( \"number_of_collections_deleted\" AS count_name, [STRUCT('collections' AS category, 'removed' AS event_name)] AS events ) ] ); From there, you can query a few things. For example, the fraction of users who completed each step of the collection flow over time: SELECT submission_date, COUNTIF(collection_flow.started_collection_creation) / COUNT(*) AS started_collection_creation, COUNTIF(collection_flow.completed_collection_creation) / COUNT(*) AS completed_collection_creation, FROM `moz-fx-data-shared-prod`.analysis.fenix_collection_funnels WHERE submission_date >= DATE_SUB(current_date, INTERVAL 28 DAY) GROUP BY submission_date Or you can see the number of collections created and deleted: SELECT submission_date, SUM(number_of_collections_created) AS number_of_collections_created, SUM(number_of_collections_deleted) AS number_of_collections_deleted, FROM `moz-fx-data-shared-prod`.analysis.fenix_collection_funnels WHERE submission_date >= DATE_SUB(current_date, INTERVAL 28 DAY) GROUP BY submission_date","title":"event_analysis"},{"location":"mozfun/event_analysis/#event_analysis","text":"These functions are specific for use with the events_daily and event_types tables. By themselves, these two tables are nearly impossible to use since the event history is compressed; however, these stored procedures should make the data accessible. The events_daily table is created as a result of two steps: 1. Map each event to a single UTF8 char which will represent it 2. Group each client-day and store a string that records, using the compressed format, that clients' event history for that day. The characters are ordered by the timestamp which they appeared that day. The best way to access this data is to create a view to do the heavy lifting. For example, to see which clients completed a certain action, you can create a view using these functions that knows what that action's representation is (using the compressed mapping from 1.) and create a regex string that checks for the presence of that event. The view makes this transparent, and allows users to simply query a boolean field representing the presence of that event on that day.","title":"event_analysis"},{"location":"mozfun/event_analysis/#extract_event_counts-udf","text":"Extract the events and their counts from an events string. This function explicitly ignores event properties, and retrieves just the counts of the top-level events.","title":"extract_event_counts (UDF)"},{"location":"mozfun/event_analysis/#usage","text":"extract_event_counts( events STRING ) events - A comma-separated events string, where each event is represented as a string of unicode chars.","title":"Usage"},{"location":"mozfun/event_analysis/#example","text":"See this dashboard for example usage.","title":"Example"},{"location":"mozfun/event_analysis/#extract_event_counts_with_properties-udf","text":"Extract events with event properties and their associated counts. Also extracts raw events and their counts. This allows for querying with and without properties in the same dashboard.","title":"extract_event_counts_with_properties (UDF)"},{"location":"mozfun/event_analysis/#usage_1","text":"extract_event_counts_with_properties( events STRING ) events - A comma-separated events string, where each event is represented as a string of unicode chars.","title":"Usage"},{"location":"mozfun/event_analysis/#example_1","text":"See this query for example usage.","title":"Example"},{"location":"mozfun/event_analysis/#caveats","text":"This function extracts both counts for events with each property, and for all events without their properties. This allows us to include both total counts for an event (with any property value), and events that don't have properties.","title":"Caveats"},{"location":"mozfun/event_analysis/#create_events_view-stored-procedure","text":"Create a view that queries the events_daily table. This view currently supports both funnels and event counts. Funnels are created as a struct, with each step in the funnel as a boolean column in the struct, indicating whether the user completed that step on that day. Event counts are simply integers.","title":"create_events_view (Stored Procedure)"},{"location":"mozfun/event_analysis/#usage_2","text":"create_events_view( view_name STRING, project STRING, dataset STRING, funnels ARRAY<STRUCT< funnel_name STRING, funnel ARRAY<STRUCT< step_name STRING, events ARRAY<STRUCT< category STRING, event_name STRING>>>>>>, counts ARRAY<STRUCT< count_name STRING, events ARRAY<STRUCT< category STRING, event_name STRING>>>> ) view_name : The name of the view that will be created. This view will be in the shared-prod project, in the analysis bucket, and so will be queryable at: sql `moz-fx-data-shared-prod`.analysis.{view_name} project : The project where the dataset is located. dataset : The dataset that must contain both the events_daily and event_types tables. funnels : An array of funnels that will be created. Each funnel has two parts: funnel_name : The name of the funnel is what the column representing the funnel will be named in the view. For example, with the value \"onboarding\" , the view can be selected as follows: sql SELECT onboarding FROM `moz-fx-data-shared-prod`.analysis.{view_name} funnel : The ordered series of steps that make up a funnel. Each step also has: step_name : Used to name the column within the funnel and represents whether the user completed that step on that day. For example, within onboarding a user may have completed_first_card as a step; this can be queried at sql SELECT onboarding.completed_first_step FROM `moz-fx-data-shared-prod`.analysis.{view_name} events : The set of events which indicate the user completed that step of the funnel. Most of the time this is a single event. Each event has a category and event_name . counts : An array of counts. Each count has two parts, similar to funnel steps: count_name : Used to name the column representing the event count. E.g. \"clicked_settings_count\" would be queried at sql SELECT clicked_settings_count FROM `moz-fx-data-shared-prod`.analysis.{view_name} events : The set of events you want to count. Each event has a category and event_name .","title":"Usage"},{"location":"mozfun/event_analysis/#recommended-pattern","text":"Because the view definitions themselves are not informative about the contents of the events fields, it is best to put your query immediately after the procedure invocation, rather than invoking the procedure and running a separate query. This STMO query is an example of doing so. This allows viewers of the query to easily interpret what the funnel and count columns represent.","title":"Recommended Pattern"},{"location":"mozfun/event_analysis/#structure-of-the-resulting-view","text":"The view will be created at `moz-fx-data-shared-prod`.analysis.{event_name}. The view will have a schema roughly matching the following: root |-- submission_date: date |-- client_id: string |-- {funnel_1_name}: record | |-- {funnel_step_1_name} boolean | |-- {funnel_step_2_name} boolean ... |-- {funnel_N_name}: record | |-- {funnel_step_M_name}: boolean |-- {count_1_name}: integer ... |-- {count_N_name}: integer ...dimensions...","title":"Structure of the Resulting View"},{"location":"mozfun/event_analysis/#funnels","text":"Each funnel will be a STRUCT with nested columns representing completion of each step The types of those columns are boolean, and represent whether the user completed that step on that day. STRUCT( completed_step_1 BOOLEAN, completed_step_2 BOOLEAN, ... ) AS funnel_name With one row per-user per-day, you can use COUNTIF(funnel_name.completed_step_N) to query these fields. See below for an example.","title":"Funnels"},{"location":"mozfun/event_analysis/#event-counts","text":"Each event count is simply an INT64 representing the number of times the user completed those events on that day. If there are multiple events represented within one count, the values are summed. For example, if you wanted to know the number of times a user opened or closed the app, you could create a single event count with those two events. event_count_name INT64","title":"Event Counts"},{"location":"mozfun/event_analysis/#examples","text":"The following creates a few fields: - collection_flow is a funnel for those that started creating a collection within Fenix, and then finished, either by adding those tabs to an existing collection or saving it as a new collection. - collection_flow_saved represents users who started the collection flow then saved it as a new collection. - number_of_collections_created is the number of collections created - number_of_collections_deleted is the number of collections deleted CALL mozfun.event_analysis.create_events_view( 'fenix_collection_funnels', 'moz-fx-data-shared-prod', 'org_mozilla_firefox', -- Funnels [ STRUCT( \"collection_flow\" AS funnel_name, [STRUCT( \"started_collection_creation\" AS step_name, [STRUCT('collections' AS category, 'tab_select_opened' AS event_name)] AS events), STRUCT( \"completed_collection_creation\" AS step_name, [STRUCT('collections' AS category, 'saved' AS event_name), STRUCT('collections' AS category, 'tabs_added' AS event_name)] AS events) ] AS funnel), STRUCT( \"collection_flow_saved\" AS funnel_name, [STRUCT( \"started_collection_creation\" AS step_name, [STRUCT('collections' AS category, 'tab_select_opened' AS event_name)] AS events), STRUCT( \"saved_collection\" AS step_name, [STRUCT('collections' AS category, 'saved' AS event_name)] AS events) ] AS funnel) ], -- Event Counts [ STRUCT( \"number_of_collections_created\" AS count_name, [STRUCT('collections' AS category, 'saved' AS event_name)] AS events ), STRUCT( \"number_of_collections_deleted\" AS count_name, [STRUCT('collections' AS category, 'removed' AS event_name)] AS events ) ] ); From there, you can query a few things. For example, the fraction of users who completed each step of the collection flow over time: SELECT submission_date, COUNTIF(collection_flow.started_collection_creation) / COUNT(*) AS started_collection_creation, COUNTIF(collection_flow.completed_collection_creation) / COUNT(*) AS completed_collection_creation, FROM `moz-fx-data-shared-prod`.analysis.fenix_collection_funnels WHERE submission_date >= DATE_SUB(current_date, INTERVAL 28 DAY) GROUP BY submission_date Or you can see the number of collections created and deleted: SELECT submission_date, SUM(number_of_collections_created) AS number_of_collections_created, SUM(number_of_collections_deleted) AS number_of_collections_deleted, FROM `moz-fx-data-shared-prod`.analysis.fenix_collection_funnels WHERE submission_date >= DATE_SUB(current_date, INTERVAL 28 DAY) GROUP BY submission_date","title":"Examples"},{"location":"mozfun/glean/","text":"glean Functions for working with Glean data. timespan_seconds (UDF) Returns the number of seconds represented by a Glean timespan struct, rounded down to full seconds. See https://mozilla.github.io/glean/book/user/metrics/timespan.html timespan_nanos (UDF) Returns the number of nanoseconds represented by a Glean timespan struct. See https://mozilla.github.io/glean/book/user/metrics/timespan.html","title":"glean"},{"location":"mozfun/glean/#glean","text":"Functions for working with Glean data.","title":"glean"},{"location":"mozfun/glean/#timespan_seconds-udf","text":"Returns the number of seconds represented by a Glean timespan struct, rounded down to full seconds. See https://mozilla.github.io/glean/book/user/metrics/timespan.html","title":"timespan_seconds (UDF)"},{"location":"mozfun/glean/#timespan_nanos-udf","text":"Returns the number of nanoseconds represented by a Glean timespan struct. See https://mozilla.github.io/glean/book/user/metrics/timespan.html","title":"timespan_nanos (UDF)"},{"location":"mozfun/hist/","text":"hist Functions for working with string encodings of histograms from desktop telemetry. percentiles (UDF) Given histogram and list of percentiles,calculate what those percentiles are for the histogram. If the histogram is empty, returns NULL. threshold_count (UDF) Return the number of recorded observations greater than threshold for the histogram. CAUTION: Does not count any buckets that have any values less than the threshold. For example, a bucket with range (1, 10) will not be counted for a threshold of 2. Use threshold that are not bucket boundaries with caution. https://github.com/mozilla/telemetry-batch-view/blob/ea0733c/src/main/scala/com/mozilla/telemetry/utils/MainPing.scala#L213-L239 normalize (UDF) Normalize a histogram. Set sum to 1, and normalize to 1 the histogram bucket counts. extract (UDF) Return a parsed struct from a string-encoded histogram. We support a variety of compact encodings as well as the classic JSON representation as sent in main pings. The built-in BigQuery JSON parsing functions are not powerful enough to handle all the logic here, so we resort to some string processing. This function could behave unexpectedly on poorly-formatted histogram JSON, but we expect that payload validation in the data pipeline should ensure that histograms are well formed, which gives us some flexibility. For more on desktop telemetry histogram structure, see: https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/collection/histograms.html The compact encodings were originally proposed in: https://docs.google.com/document/d/1k_ji_1DB6htgtXnPpMpa7gX0klm-DGV5NMY7KkvVB00/edit# SELECT mozfun.hist.extract( '{\"bucket_count\":3,\"histogram_type\":4,\"sum\":1,\"range\":[1,2],\"values\":{\"0\":1,\"1\":0}}' ).sum -- 1 SELECT mozfun.hist.extract('5').sum -- 5 merge (UDF) Merge an array of histograms into a single histogram. The histogram values will be summed per-bucket The count will be summed Other fields will take the mode_last mean (UDF) Given histogram h, return floor(mean) of the measurements in the bucket. That is, the histogram sum divided by the number of measurements taken. https://github.com/mozilla/telemetry-batch-view/blob/ea0733c/src/main/scala/com/mozilla/telemetry/utils/MainPing.scala#L292-L307","title":"hist"},{"location":"mozfun/hist/#hist","text":"Functions for working with string encodings of histograms from desktop telemetry.","title":"hist"},{"location":"mozfun/hist/#percentiles-udf","text":"Given histogram and list of percentiles,calculate what those percentiles are for the histogram. If the histogram is empty, returns NULL.","title":"percentiles (UDF)"},{"location":"mozfun/hist/#threshold_count-udf","text":"Return the number of recorded observations greater than threshold for the histogram. CAUTION: Does not count any buckets that have any values less than the threshold. For example, a bucket with range (1, 10) will not be counted for a threshold of 2. Use threshold that are not bucket boundaries with caution. https://github.com/mozilla/telemetry-batch-view/blob/ea0733c/src/main/scala/com/mozilla/telemetry/utils/MainPing.scala#L213-L239","title":"threshold_count (UDF)"},{"location":"mozfun/hist/#normalize-udf","text":"Normalize a histogram. Set sum to 1, and normalize to 1 the histogram bucket counts.","title":"normalize (UDF)"},{"location":"mozfun/hist/#extract-udf","text":"Return a parsed struct from a string-encoded histogram. We support a variety of compact encodings as well as the classic JSON representation as sent in main pings. The built-in BigQuery JSON parsing functions are not powerful enough to handle all the logic here, so we resort to some string processing. This function could behave unexpectedly on poorly-formatted histogram JSON, but we expect that payload validation in the data pipeline should ensure that histograms are well formed, which gives us some flexibility. For more on desktop telemetry histogram structure, see: https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/collection/histograms.html The compact encodings were originally proposed in: https://docs.google.com/document/d/1k_ji_1DB6htgtXnPpMpa7gX0klm-DGV5NMY7KkvVB00/edit# SELECT mozfun.hist.extract( '{\"bucket_count\":3,\"histogram_type\":4,\"sum\":1,\"range\":[1,2],\"values\":{\"0\":1,\"1\":0}}' ).sum -- 1 SELECT mozfun.hist.extract('5').sum -- 5","title":"extract (UDF)"},{"location":"mozfun/hist/#merge-udf","text":"Merge an array of histograms into a single histogram. The histogram values will be summed per-bucket The count will be summed Other fields will take the mode_last","title":"merge (UDF)"},{"location":"mozfun/hist/#mean-udf","text":"Given histogram h, return floor(mean) of the measurements in the bucket. That is, the histogram sum divided by the number of measurements taken. https://github.com/mozilla/telemetry-batch-view/blob/ea0733c/src/main/scala/com/mozilla/telemetry/utils/MainPing.scala#L292-L307","title":"mean (UDF)"},{"location":"mozfun/json/","text":"json Functions for parsing Mozilla-specific JSON data types. mode_last (UDF) Returns the most frequently occuring element in an array of json-compatible elements. In the case of multiple values tied for the highest count, it returns the value that appears latest in the array. Nulls are ignored. extract_int_map (UDF) Returns an array of key/value structs from a string representing a JSON map. Both keys and values are cast to integers. This is the format for the \"values\" field in the desktop telemetry histogram JSON representation.","title":"json"},{"location":"mozfun/json/#json","text":"Functions for parsing Mozilla-specific JSON data types.","title":"json"},{"location":"mozfun/json/#mode_last-udf","text":"Returns the most frequently occuring element in an array of json-compatible elements. In the case of multiple values tied for the highest count, it returns the value that appears latest in the array. Nulls are ignored.","title":"mode_last (UDF)"},{"location":"mozfun/json/#extract_int_map-udf","text":"Returns an array of key/value structs from a string representing a JSON map. Both keys and values are cast to integers. This is the format for the \"values\" field in the desktop telemetry histogram JSON representation.","title":"extract_int_map (UDF)"},{"location":"mozfun/map/","text":"map Functions for working with arrays of key/value structs. mode_last (UDF) Combine entries from multiple maps, determine the value for each key using mozfun.stats.mode_last. get_key_with_null (UDF) Fetch the value associated with a given key from an array of key/value structs. Because map types aren't available in BigQuery, we model maps as arrays of structs instead, and this function provides map-like access to such fields. This version matches NULL keys as well. get_key (UDF) Fetch the value associated with a given key from an array of key/value structs. Because map types aren't available in BigQuery, we model maps as arrays of structs instead, and this function provides map-like access to such fields. sum (UDF) Return the sum of values by key in an array of map entries. The expected schema for entries is ARRAY >, where the type for value must be supported by SUM, which allows numeric data types INT64, NUMERIC, and FLOAT64.","title":"map"},{"location":"mozfun/map/#map","text":"Functions for working with arrays of key/value structs.","title":"map"},{"location":"mozfun/map/#mode_last-udf","text":"Combine entries from multiple maps, determine the value for each key using mozfun.stats.mode_last.","title":"mode_last (UDF)"},{"location":"mozfun/map/#get_key_with_null-udf","text":"Fetch the value associated with a given key from an array of key/value structs. Because map types aren't available in BigQuery, we model maps as arrays of structs instead, and this function provides map-like access to such fields. This version matches NULL keys as well.","title":"get_key_with_null (UDF)"},{"location":"mozfun/map/#get_key-udf","text":"Fetch the value associated with a given key from an array of key/value structs. Because map types aren't available in BigQuery, we model maps as arrays of structs instead, and this function provides map-like access to such fields.","title":"get_key (UDF)"},{"location":"mozfun/map/#sum-udf","text":"Return the sum of values by key in an array of map entries. The expected schema for entries is ARRAY >, where the type for value must be supported by SUM, which allows numeric data types INT64, NUMERIC, and FLOAT64.","title":"sum (UDF)"},{"location":"mozfun/norm/","text":"norm Functions for normalizing data. product_info (UDF) Returns a normalized product name and a canonical_name for a product based on the raw app_name and normalized_os values that appear in pings. The returned product name is intended to be readable and unambiguous, but short and easy to type. This value is suitable for use as a key in derived tables. The returned canonical_name is more verbose and is suited for displaying in visualizations. The returned struct also contains boolean contributes_to_2020_kpi as the canonical reference for whether the given application is included in KPI reporting. Additional fields may be added for future years. The normalized_os value that's passed in should be the top-level normalized_os value present in any ping table or you may want to wrap a raw value in mozfun.norm.os like mozfun.norm.product_info(app_name, mozfun.norm.os(os)) . For legacy telemetry pings like main ping for desktop and core ping for mobile products, app_name should come from the submission URI (stored as metadata.uri.app_name in BigQuery ping tables). For Glean pings, the concept of an app_name doesn't exist, since pings from different applications are routed to different BigQuery datasets. Instead, the app_name send in for Glean pings should be the same value as what's expected for product . So, a view on top of pings from Fenix should pass in \"Fenix\" for app_name . This function also tolerates passing in a product value as app_name so that this function is still useful for derived tables which have thrown away the raw app_name value. The mappings are as follows: app_name normalized_os product canonical_name 2019 2020 Firefox * Firefox Firefox for Desktop true true Fenix Android Fenix Firefox for Android (Fenix) true true Fennec Android Fennec Firefox for Android (Fennec) true true Firefox Preview Android Firefox Preview Firefox Preview for Android true true Fennec iOS Firefox iOS Firefox for iOS true true FirefoxForFireTV Android Firefox Fire TV Firefox for Fire TV false false FirefoxConnect Android Firefox Echo Firefox for Echo Show true true Zerda Android Firefox Lite Firefox Lite true true Zerda_cn Android Firefox Lite CN Firefox Lite (China) false false Focus Android Focus Android Firefox Focus for Android true true Focus iOS Focus iOS Firefox Focus for iOS true true Klar Android Klar Android Firefox Klar for Android false false Klar iOS Klar iOS Firefox Klar for iOS false false Lockbox Android Lockwise Android Lockwise for Android true true Lockbox iOS Lockwise iOS Lockwise for iOS true true FirefoxReality* Android Firefox Reality Firefox Reality true true os (UDF) Normalize an operating system string to one of the three major desktop platforms, one of the two major mobile platforms, or \"Other\". This is a reimplementation of logic used in the data pipeline > to populate normalized_os . metadata (UDF) Accepts a pipeline metadata struct as input and returns a modified struct that includes a few parsed or normalized variants of the input metadata fields. fenix_app_info (UDF) Returns canonical, human-understandable identification info for Fenix sources. The Glean telemetry library for Android by design routes pings based on the Play Store appId value of the published application. As of August 2020, there have been 5 separate Play Store appId values associated with different builds of Fenix, each corresponding to different datasets in BigQuery, and the mapping of appId to logical app names (Firefox vs. Firefox Preview) and channel names (nightly, beta, or release) has changed over time; see the spreadsheet of naming history for Mozilla's mobile browsers .> This function is intended as the source of truth for how to map a specific ping in BigQuery to a logical app names and channel. It should be expected that the output of this function may evolve over time. If we rename a product or channel, we may choose to update the values here so that analyses consistently get the new name. The first argument ( app_id ) can be fairly fuzzy; it is tolerant of actual Google Play Store appId values like 'org.mozilla.firefox_beta' (mix of periods and underscores) as well as BigQuery dataset names with suffixes like 'org_mozilla_firefox_beta_stable'. The second argument ( app_build_id ) should be the value in client_info.app_build. The function returns a STRUCT that contains the logical app_name and channel as well as the Play Store app_id in the canonical form which would appear in Play Store URLs. Note that the naming of Fenix applications changed on 2020-07-03, so to get a continuous view of the pings associated with a logical app channel, you may need to union together tables from multiple BigQuery datasets. To see data for all Fenix channels together, it is necessary to union together tables from all 5 datasets. For basic usage information, consider using telemetry.fenix_clients_last_seen which already handles the union. Otherwise, see the example below as a template for how construct a custom union. Mapping of channels to datasets: release: org_mozilla_firefox beta: org_mozilla_firefox_beta (current) and org_mozilla_fenix nightly: org_mozilla_fenix (current), org_mozilla_fennec_aurora , and org_mozilla_fenix_nightly -- Example of a query over all Fenix builds advertised as \"Firefox Beta\" CREATE TEMP FUNCTION extract_fields(app_id STRING, m ANY TYPE) AS ( ( SELECT AS STRUCT m.submission_timestamp, m.metrics.string.geckoview_version, mozfun.norm.fenix_app_info(app_id, m.client_info.app_build).* ) ); WITH base AS ( SELECT extract_fields('org_mozilla_firefox_beta', m).* FROM org_mozilla_firefox_beta.metrics AS m UNION ALL SELECT extract_fields('org_mozilla_fenix', m).* FROM org_mozilla_fenix.metrics AS m ) SELECT DATE(submission_timestamp) AS submission_date, geckoview_version, COUNT(*) FROM base WHERE app_name = 'Fenix' -- excludes 'Firefox Preview' AND channel = 'beta' AND DATE(submission_timestamp) = '2020-08-01' GROUP BY submission_date, geckoview_version glean_baseline_client_info (UDF) Accepts a glean client_info struct as input and returns a modified struct that includes a few parsed or normalized variants of the input fields. glean_ping_info (UDF) Accepts a glean ping_info struct as input and returns a modified struct that includes a few parsed or normalized variants of the input fields.","title":"norm"},{"location":"mozfun/norm/#norm","text":"Functions for normalizing data.","title":"norm"},{"location":"mozfun/norm/#product_info-udf","text":"Returns a normalized product name and a canonical_name for a product based on the raw app_name and normalized_os values that appear in pings. The returned product name is intended to be readable and unambiguous, but short and easy to type. This value is suitable for use as a key in derived tables. The returned canonical_name is more verbose and is suited for displaying in visualizations. The returned struct also contains boolean contributes_to_2020_kpi as the canonical reference for whether the given application is included in KPI reporting. Additional fields may be added for future years. The normalized_os value that's passed in should be the top-level normalized_os value present in any ping table or you may want to wrap a raw value in mozfun.norm.os like mozfun.norm.product_info(app_name, mozfun.norm.os(os)) . For legacy telemetry pings like main ping for desktop and core ping for mobile products, app_name should come from the submission URI (stored as metadata.uri.app_name in BigQuery ping tables). For Glean pings, the concept of an app_name doesn't exist, since pings from different applications are routed to different BigQuery datasets. Instead, the app_name send in for Glean pings should be the same value as what's expected for product . So, a view on top of pings from Fenix should pass in \"Fenix\" for app_name . This function also tolerates passing in a product value as app_name so that this function is still useful for derived tables which have thrown away the raw app_name value. The mappings are as follows: app_name normalized_os product canonical_name 2019 2020 Firefox * Firefox Firefox for Desktop true true Fenix Android Fenix Firefox for Android (Fenix) true true Fennec Android Fennec Firefox for Android (Fennec) true true Firefox Preview Android Firefox Preview Firefox Preview for Android true true Fennec iOS Firefox iOS Firefox for iOS true true FirefoxForFireTV Android Firefox Fire TV Firefox for Fire TV false false FirefoxConnect Android Firefox Echo Firefox for Echo Show true true Zerda Android Firefox Lite Firefox Lite true true Zerda_cn Android Firefox Lite CN Firefox Lite (China) false false Focus Android Focus Android Firefox Focus for Android true true Focus iOS Focus iOS Firefox Focus for iOS true true Klar Android Klar Android Firefox Klar for Android false false Klar iOS Klar iOS Firefox Klar for iOS false false Lockbox Android Lockwise Android Lockwise for Android true true Lockbox iOS Lockwise iOS Lockwise for iOS true true FirefoxReality* Android Firefox Reality Firefox Reality true true","title":"product_info (UDF)"},{"location":"mozfun/norm/#os-udf","text":"Normalize an operating system string to one of the three major desktop platforms, one of the two major mobile platforms, or \"Other\". This is a reimplementation of logic used in the data pipeline > to populate normalized_os .","title":"os (UDF)"},{"location":"mozfun/norm/#metadata-udf","text":"Accepts a pipeline metadata struct as input and returns a modified struct that includes a few parsed or normalized variants of the input metadata fields.","title":"metadata (UDF)"},{"location":"mozfun/norm/#fenix_app_info-udf","text":"Returns canonical, human-understandable identification info for Fenix sources. The Glean telemetry library for Android by design routes pings based on the Play Store appId value of the published application. As of August 2020, there have been 5 separate Play Store appId values associated with different builds of Fenix, each corresponding to different datasets in BigQuery, and the mapping of appId to logical app names (Firefox vs. Firefox Preview) and channel names (nightly, beta, or release) has changed over time; see the spreadsheet of naming history for Mozilla's mobile browsers .> This function is intended as the source of truth for how to map a specific ping in BigQuery to a logical app names and channel. It should be expected that the output of this function may evolve over time. If we rename a product or channel, we may choose to update the values here so that analyses consistently get the new name. The first argument ( app_id ) can be fairly fuzzy; it is tolerant of actual Google Play Store appId values like 'org.mozilla.firefox_beta' (mix of periods and underscores) as well as BigQuery dataset names with suffixes like 'org_mozilla_firefox_beta_stable'. The second argument ( app_build_id ) should be the value in client_info.app_build. The function returns a STRUCT that contains the logical app_name and channel as well as the Play Store app_id in the canonical form which would appear in Play Store URLs. Note that the naming of Fenix applications changed on 2020-07-03, so to get a continuous view of the pings associated with a logical app channel, you may need to union together tables from multiple BigQuery datasets. To see data for all Fenix channels together, it is necessary to union together tables from all 5 datasets. For basic usage information, consider using telemetry.fenix_clients_last_seen which already handles the union. Otherwise, see the example below as a template for how construct a custom union. Mapping of channels to datasets: release: org_mozilla_firefox beta: org_mozilla_firefox_beta (current) and org_mozilla_fenix nightly: org_mozilla_fenix (current), org_mozilla_fennec_aurora , and org_mozilla_fenix_nightly -- Example of a query over all Fenix builds advertised as \"Firefox Beta\" CREATE TEMP FUNCTION extract_fields(app_id STRING, m ANY TYPE) AS ( ( SELECT AS STRUCT m.submission_timestamp, m.metrics.string.geckoview_version, mozfun.norm.fenix_app_info(app_id, m.client_info.app_build).* ) ); WITH base AS ( SELECT extract_fields('org_mozilla_firefox_beta', m).* FROM org_mozilla_firefox_beta.metrics AS m UNION ALL SELECT extract_fields('org_mozilla_fenix', m).* FROM org_mozilla_fenix.metrics AS m ) SELECT DATE(submission_timestamp) AS submission_date, geckoview_version, COUNT(*) FROM base WHERE app_name = 'Fenix' -- excludes 'Firefox Preview' AND channel = 'beta' AND DATE(submission_timestamp) = '2020-08-01' GROUP BY submission_date, geckoview_version","title":"fenix_app_info (UDF)"},{"location":"mozfun/norm/#glean_baseline_client_info-udf","text":"Accepts a glean client_info struct as input and returns a modified struct that includes a few parsed or normalized variants of the input fields.","title":"glean_baseline_client_info (UDF)"},{"location":"mozfun/norm/#glean_ping_info-udf","text":"Accepts a glean ping_info struct as input and returns a modified struct that includes a few parsed or normalized variants of the input fields.","title":"glean_ping_info (UDF)"},{"location":"mozfun/overview/","text":"mozfun mozfun is a public GCP project provisioning publicly accessible user-defined functions (UDFs) and other function-like resources.","title":"mozfun"},{"location":"mozfun/overview/#mozfun","text":"mozfun is a public GCP project provisioning publicly accessible user-defined functions (UDFs) and other function-like resources.","title":"mozfun"},{"location":"mozfun/stats/","text":"stats Statistics functions. mode_last (UDF) Returns the most frequently occuring element in an array. In the case of multiple values tied for the highest count, it returns the value that appears latest in the array. Nulls are ignored. See also: stats.mode_last_retain_nulls , which retains nulls. mode_last_retain_nulls (UDF) Returns the most frequently occuring element in an array. In the case of multiple values tied for the highest count, it returns the value that appears latest in the array. Nulls are retained. See also: `stats.mode_last, which ignores nulls.","title":"stats"},{"location":"mozfun/stats/#stats","text":"Statistics functions.","title":"stats"},{"location":"mozfun/stats/#mode_last-udf","text":"Returns the most frequently occuring element in an array. In the case of multiple values tied for the highest count, it returns the value that appears latest in the array. Nulls are ignored. See also: stats.mode_last_retain_nulls , which retains nulls.","title":"mode_last (UDF)"},{"location":"mozfun/stats/#mode_last_retain_nulls-udf","text":"Returns the most frequently occuring element in an array. In the case of multiple values tied for the highest count, it returns the value that appears latest in the array. Nulls are retained. See also: `stats.mode_last, which ignores nulls.","title":"mode_last_retain_nulls (UDF)"}]}